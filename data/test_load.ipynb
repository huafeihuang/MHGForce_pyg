{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import ipdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "from torch_sparse import coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# if args.cuda:\n",
    "# \ttorch.cuda.manual_seed(seed)\n",
    "# 为所有GPU设置\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[[ -V- | -E- ]      [ -E- | -V- ]]\n",
    "'''\n",
    "\n",
    "def load_LE_dataset(path, dataset):\n",
    "    # load edges, features, and labels.\n",
    "    print('Loading {} dataset...'.format(dataset))\n",
    "    \n",
    "    file_name = f'{dataset}.content'\n",
    "    p2idx_features_labels = os.path.join(path, file_name)\n",
    "    idx_features_labels = np.genfromtxt(p2idx_features_labels,\n",
    "                                        dtype=np.dtype(str))\n",
    "    # features = np.array(idx_features_labels[:, 1:-1])\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "#     labels = encode_onehot(idx_features_labels[:, -1])\n",
    "    labels = torch.LongTensor(idx_features_labels[:, -1].astype(float))\n",
    "\n",
    "\n",
    "    print ('load features')\n",
    "\n",
    "    # build graph\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    \n",
    "    file_name = f'{dataset}.edges'\n",
    "    p2edges_unordered = os.path.join(path, file_name)\n",
    "    edges_unordered = np.genfromtxt(p2edges_unordered,\n",
    "                                    dtype=np.int32)\n",
    "    \n",
    "    \n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "\n",
    "    print ('load edges')\n",
    "\n",
    "\n",
    "    projected_features = torch.FloatTensor(np.array(features.todense()))\n",
    "\n",
    "    \n",
    "    # From adjacency matrix to edge_list\n",
    "    edge_index = edges.T \n",
    "    assert edge_index[0].max() == edge_index[1].min() - 1\n",
    "\n",
    "    # check if values in edge_index is consecutive. i.e. no missing value for node_id/he_id.\n",
    "    assert len(np.unique(edge_index)) == edge_index.max() + 1\n",
    "    \n",
    "    num_nodes = edge_index[0].max() + 1\n",
    "    num_he = edge_index[1].max() - num_nodes + 1\n",
    "    \n",
    "    edge_index = np.hstack((edge_index, edge_index[::-1, :]))\n",
    "    \n",
    "    # build torch data class\n",
    "    data = Data(\n",
    "            x = torch.FloatTensor(np.array(features[:num_nodes].todense())), \n",
    "            edge_index = torch.LongTensor(edge_index),\n",
    "            y = labels[:num_nodes])\n",
    "\n",
    "    # data.coalesce()\n",
    "    # There might be errors if edge_index.max() != num_nodes.\n",
    "    # used user function to override the default function.\n",
    "    # the following will also sort the edge_index and remove duplicates. \n",
    "    total_num_node_id_he_id = len(np.unique(edge_index))\n",
    "    data.edge_index, data.edge_attr = coalesce(data.edge_index, \n",
    "            None, \n",
    "            total_num_node_id_he_id, \n",
    "            total_num_node_id_he_id)\n",
    "            \n",
    "    \n",
    "    data.num_features = data.x.shape[-1]\n",
    "    data.num_classes = len(np.unique(labels[:num_nodes].numpy()))\n",
    "    data.num_nodes = num_nodes\n",
    "    data.num_hyperedges = num_he\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./20newsW100/' # 67, 成功\n",
    "dataset='20newsW100'\n",
    "# zoo/Mushroom/20newsW100/NTU2012/\n",
    "data = load_LE_dataset(path,dataset)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cornell_dataset(path, dataset, feature_noise = 0.1, feature_dim = None):\n",
    "    '''\n",
    "    this will read the yelp dataset from source files, and convert it edge_list to \n",
    "    [[ -V- | -E- ]\n",
    "     [ -E- | -V- ]]\n",
    "\n",
    "    each node is a restaurant, a hyperedge represent a set of restaurants one user had been to.\n",
    "\n",
    "    node features:\n",
    "        - add gaussian noise with sigma = nosie, mean = one hot coded label.\n",
    "\n",
    "    node label:\n",
    "        - average stars from 2-10, converted from original stars which is binned in x.5, min stars = 1\n",
    "    '''\n",
    "    print(f'Loading hypergraph dataset from cornell: {dataset}')\n",
    "\n",
    "    # first load node labels\n",
    "    df_labels = pd.read_csv(os.path.join(path, f'node-labels-{dataset}.txt'), names = ['node_label'])\n",
    "    num_nodes = df_labels.shape[0]\n",
    "    labels = df_labels.values.flatten()\n",
    "\n",
    "    # then create node features.\n",
    "    num_classes = df_labels.values.max()\n",
    "    features = np.zeros((num_nodes, num_classes))\n",
    "\n",
    "    features[np.arange(num_nodes), labels - 1] = 1\n",
    "    if feature_dim is not None:\n",
    "        num_row, num_col = features.shape\n",
    "        zero_col = np.zeros((num_row, feature_dim - num_col), dtype = features.dtype)\n",
    "        features = np.hstack((features, zero_col))\n",
    "\n",
    "    features = np.random.normal(features, feature_noise, features.shape)# 没有特征数据，形状和标签类数一样\n",
    "    print(f'number of nodes:{num_nodes}, feature dimension: {features.shape[1]}')\n",
    "\n",
    "    features = torch.FloatTensor(features)\n",
    "    labels = torch.LongTensor(labels)\n",
    "    labels = labels - labels.min() # shift label to 0\n",
    "\n",
    "    # The last, load hypergraph.\n",
    "    # Corenll datasets are stored in lines of hyperedges. Each line is the set of nodes for that edge.\n",
    "    p2hyperedge_list = os.path.join(path, f'hyperedges-{dataset}.txt')\n",
    "    node_list = []\n",
    "    he_list = []\n",
    "    he_id = num_nodes\n",
    "\n",
    "    with open(p2hyperedge_list, 'r') as f:\n",
    "        for line in f:\n",
    "            if line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            cur_set = line.split(',')\n",
    "            cur_set = [int(x) for x in cur_set]\n",
    "\n",
    "            node_list += cur_set\n",
    "            he_list += [he_id] * len(cur_set)\n",
    "            he_id += 1\n",
    "    # shift node_idx to start with 0.\n",
    "    node_idx_min = np.min(node_list)\n",
    "    node_list = [x - node_idx_min for x in node_list]\n",
    "\n",
    "    edge_index = [node_list + he_list, \n",
    "                  he_list + node_list]\n",
    "\n",
    "    edge_index = torch.LongTensor(edge_index)\n",
    "\n",
    "    data = Data(x = features,\n",
    "                edge_index = edge_index,\n",
    "                y = labels)\n",
    "    assert data.y.min().item() == 0\n",
    "\n",
    "    # data.coalesce()\n",
    "    # There might be errors if edge_index.max() != num_nodes.\n",
    "    # used user function to override the default function.\n",
    "    # the following will also sort the edge_index and remove duplicates. \n",
    "    total_num_node_id_he_id = edge_index.max() + 1\n",
    "    data.edge_index, data.edge_attr = coalesce(data.edge_index, \n",
    "            None, \n",
    "            total_num_node_id_he_id, \n",
    "            total_num_node_id_he_id)\n",
    "\n",
    "    data.num_features = features.shape[-1]\n",
    "    data.num_classes = len(np.unique(labels.numpy()))\n",
    "    data.num_nodes = num_nodes\n",
    "    data.num_hyperedges = he_id - num_nodes\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hypergraph dataset from cornell: house-committees\n",
      "number of nodes:1290, feature dimension: 2\n",
      "Data(x=[1290, 2], edge_index=[2, 23686], y=[1290], num_features=2, num_classes=2, num_nodes=1290, num_hyperedges=341)\n"
     ]
    }
   ],
   "source": [
    "path='./house-committees/' # 67, 成功\n",
    "dataset='house-committees'\n",
    "# zoo/Mushroom/20newsW100/NTU2012/\n",
    "data = load_cornell_dataset(path,dataset)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_mask(total_size, indices):\n",
    "    mask = torch.zeros(total_size)\n",
    "    mask[indices] = 1\n",
    "    return mask.byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_train_test_idx(label, train_prop=.5, valid_prop=.25, ignore_negative=True, balance=False):\n",
    "    \"\"\" Adapted from https://github.com/CUAI/Non-Homophily-Benchmarks\"\"\"\n",
    "    \"\"\" randomly splits label into train/valid/test splits \"\"\"\n",
    "    if ignore_negative:\n",
    "        labeled_nodes = torch.where(label != -1)[0]\n",
    "    else:\n",
    "        labeled_nodes = label\n",
    "\n",
    "    n = labeled_nodes.shape[0]\n",
    "\n",
    "    if not balance:\n",
    "        train_num = int(n * train_prop)\n",
    "        valid_num = int(n * valid_prop)\n",
    "\n",
    "        perm = torch.as_tensor(np.random.permutation(n))\n",
    "\n",
    "        train_indices = perm[:train_num]\n",
    "        val_indices = perm[train_num:train_num + valid_num]\n",
    "        test_indices = perm[train_num + valid_num:]\n",
    "\n",
    "        if not ignore_negative:\n",
    "            return train_indices, val_indices, test_indices\n",
    "\n",
    "        train_idx = labeled_nodes[train_indices]\n",
    "        valid_idx = labeled_nodes[val_indices]\n",
    "        test_idx = labeled_nodes[test_indices]\n",
    "\n",
    "        split_idx = {'train': train_idx,\n",
    "                     'valid': valid_idx,\n",
    "                     'test': test_idx}\n",
    "    else:\n",
    "        #         ipdb.set_trace()\n",
    "        indices = []\n",
    "        for i in range(label.max()+1):\n",
    "            index = torch.where((label == i))[0].view(-1)\n",
    "            index = index[torch.randperm(index.size(0))]\n",
    "            indices.append(index)\n",
    "\n",
    "        percls_trn = int(train_prop/(label.max()+1)*len(labeled_nodes))\n",
    "        val_lb = int(valid_prop*len(labeled_nodes))\n",
    "        train_idx = torch.cat([i[:percls_trn] for i in indices], dim=0)\n",
    "        rest_index = torch.cat([i[percls_trn:] for i in indices], dim=0)\n",
    "        rest_index = rest_index[torch.randperm(rest_index.size(0))]\n",
    "        valid_idx = rest_index[:val_lb]\n",
    "        test_idx = rest_index[val_lb:]\n",
    "        split_idx = {'train': train_idx,\n",
    "                     'valid': valid_idx,\n",
    "                     'test': test_idx}\n",
    "    return split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_train_test_idx_pure(label, train_prop=.5, ignore_negative=True, balance=False):\n",
    "    \"\"\" Adapted from https://github.com/CUAI/Non-Homophily-Benchmarks\"\"\"\n",
    "    \"\"\" randomly splits label into train/valid/test splits \"\"\"\n",
    "    if ignore_negative:\n",
    "        labeled_nodes = torch.where(label != -1)[0]\n",
    "    else:\n",
    "        labeled_nodes = label\n",
    "\n",
    "    n = labeled_nodes.shape[0]\n",
    "\n",
    "    if not balance:\n",
    "        train_num = int(n * train_prop)\n",
    "        # valid_num = int(n * valid_prop)\n",
    "\n",
    "        perm = torch.as_tensor(np.random.permutation(n))\n",
    "\n",
    "        train_indices = perm[:train_num]\n",
    "        # val_indices = perm[train_num:train_num + valid_num]\n",
    "        test_indices = perm[train_num:]\n",
    "\n",
    "        if not ignore_negative:\n",
    "            return train_indices, test_indices\n",
    "\n",
    "        train_idx = labeled_nodes[train_indices]\n",
    "        # valid_idx = labeled_nodes[val_indices]\n",
    "        test_idx = labeled_nodes[test_indices]\n",
    "\n",
    "        split_idx = {'train': train_idx,\n",
    "                     'test': test_idx}\n",
    "    else:\n",
    "        #         ipdb.set_trace()\n",
    "        indices = []\n",
    "        for i in range(label.max()+1):\n",
    "            index = torch.where((label == i))[0].view(-1)\n",
    "            index = index[torch.randperm(index.size(0))]\n",
    "            indices.append(index)\n",
    "\n",
    "        percls_trn = int(train_prop/(label.max()+1)*len(labeled_nodes))\n",
    "        # val_lb = int(valid_prop*len(labeled_nodes))\n",
    "        train_idx = torch.cat([i[:percls_trn] for i in indices], dim=0)\n",
    "        rest_index = torch.cat([i[percls_trn:] for i in indices], dim=0)\n",
    "        rest_index = rest_index[torch.randperm(rest_index.size(0))]\n",
    "        # valid_idx = rest_index[:val_lb]\n",
    "        test_idx = rest_index[percls_trn:]\n",
    "        split_idx = {'train': train_idx,\n",
    "                     'test': test_idx}\n",
    "    return split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./house-committees/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_path = path+'splits/'\n",
    "if not os.path.isdir(split_path):\n",
    "    os.makedirs(split_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    idx_list = rand_train_test_idx_pure(data.y)\n",
    "    split_idxs = {'train': idx_list['train'].tolist(),'test': idx_list['test'].tolist()}\n",
    "    with open(split_path+str(i)+\".pickle\", \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(split_idxs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name = split_path+'1.pickle'\n",
    "Splits=None\n",
    "with open(split_name, 'rb') as H: \n",
    "    Splits = pickle.load(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [893,\n",
       "  990,\n",
       "  1241,\n",
       "  222,\n",
       "  265,\n",
       "  169,\n",
       "  88,\n",
       "  287,\n",
       "  1119,\n",
       "  503,\n",
       "  1047,\n",
       "  1074,\n",
       "  756,\n",
       "  473,\n",
       "  862,\n",
       "  1246,\n",
       "  627,\n",
       "  825,\n",
       "  1060,\n",
       "  846,\n",
       "  642,\n",
       "  486,\n",
       "  383,\n",
       "  330,\n",
       "  472,\n",
       "  443,\n",
       "  39,\n",
       "  896,\n",
       "  49,\n",
       "  730,\n",
       "  316,\n",
       "  991,\n",
       "  936,\n",
       "  341,\n",
       "  532,\n",
       "  134,\n",
       "  935,\n",
       "  427,\n",
       "  163,\n",
       "  423,\n",
       "  1108,\n",
       "  290,\n",
       "  386,\n",
       "  748,\n",
       "  1038,\n",
       "  798,\n",
       "  764,\n",
       "  84,\n",
       "  742,\n",
       "  662,\n",
       "  1012,\n",
       "  363,\n",
       "  937,\n",
       "  527,\n",
       "  1098,\n",
       "  784,\n",
       "  1210,\n",
       "  728,\n",
       "  184,\n",
       "  467,\n",
       "  979,\n",
       "  268,\n",
       "  74,\n",
       "  1256,\n",
       "  375,\n",
       "  1143,\n",
       "  1112,\n",
       "  704,\n",
       "  982,\n",
       "  669,\n",
       "  820,\n",
       "  1229,\n",
       "  111,\n",
       "  930,\n",
       "  809,\n",
       "  441,\n",
       "  1201,\n",
       "  1034,\n",
       "  376,\n",
       "  1117,\n",
       "  311,\n",
       "  21,\n",
       "  626,\n",
       "  1002,\n",
       "  668,\n",
       "  638,\n",
       "  883,\n",
       "  71,\n",
       "  1071,\n",
       "  1076,\n",
       "  464,\n",
       "  391,\n",
       "  147,\n",
       "  941,\n",
       "  188,\n",
       "  947,\n",
       "  390,\n",
       "  26,\n",
       "  551,\n",
       "  148,\n",
       "  465,\n",
       "  580,\n",
       "  346,\n",
       "  1141,\n",
       "  540,\n",
       "  415,\n",
       "  884,\n",
       "  1070,\n",
       "  961,\n",
       "  335,\n",
       "  1169,\n",
       "  1248,\n",
       "  515,\n",
       "  200,\n",
       "  468,\n",
       "  1155,\n",
       "  1258,\n",
       "  656,\n",
       "  226,\n",
       "  479,\n",
       "  605,\n",
       "  1109,\n",
       "  1097,\n",
       "  744,\n",
       "  116,\n",
       "  213,\n",
       "  251,\n",
       "  332,\n",
       "  1046,\n",
       "  130,\n",
       "  240,\n",
       "  1178,\n",
       "  187,\n",
       "  1279,\n",
       "  878,\n",
       "  136,\n",
       "  1285,\n",
       "  783,\n",
       "  272,\n",
       "  647,\n",
       "  1026,\n",
       "  1211,\n",
       "  619,\n",
       "  470,\n",
       "  1239,\n",
       "  1219,\n",
       "  424,\n",
       "  475,\n",
       "  24,\n",
       "  331,\n",
       "  463,\n",
       "  806,\n",
       "  591,\n",
       "  803,\n",
       "  844,\n",
       "  869,\n",
       "  609,\n",
       "  886,\n",
       "  568,\n",
       "  925,\n",
       "  1275,\n",
       "  343,\n",
       "  308,\n",
       "  502,\n",
       "  433,\n",
       "  233,\n",
       "  141,\n",
       "  454,\n",
       "  976,\n",
       "  963,\n",
       "  28,\n",
       "  359,\n",
       "  902,\n",
       "  955,\n",
       "  364,\n",
       "  676,\n",
       "  724,\n",
       "  633,\n",
       "  1174,\n",
       "  949,\n",
       "  614,\n",
       "  1039,\n",
       "  675,\n",
       "  426,\n",
       "  1195,\n",
       "  573,\n",
       "  397,\n",
       "  1200,\n",
       "  197,\n",
       "  1087,\n",
       "  44,\n",
       "  1259,\n",
       "  709,\n",
       "  811,\n",
       "  96,\n",
       "  157,\n",
       "  672,\n",
       "  1016,\n",
       "  1044,\n",
       "  861,\n",
       "  315,\n",
       "  407,\n",
       "  1019,\n",
       "  352,\n",
       "  314,\n",
       "  4,\n",
       "  670,\n",
       "  1222,\n",
       "  645,\n",
       "  99,\n",
       "  779,\n",
       "  823,\n",
       "  948,\n",
       "  135,\n",
       "  664,\n",
       "  1035,\n",
       "  969,\n",
       "  403,\n",
       "  144,\n",
       "  888,\n",
       "  808,\n",
       "  487,\n",
       "  802,\n",
       "  1015,\n",
       "  710,\n",
       "  1232,\n",
       "  285,\n",
       "  712,\n",
       "  794,\n",
       "  115,\n",
       "  1093,\n",
       "  13,\n",
       "  338,\n",
       "  101,\n",
       "  1175,\n",
       "  1266,\n",
       "  731,\n",
       "  889,\n",
       "  77,\n",
       "  385,\n",
       "  202,\n",
       "  623,\n",
       "  296,\n",
       "  217,\n",
       "  320,\n",
       "  1073,\n",
       "  215,\n",
       "  824,\n",
       "  447,\n",
       "  667,\n",
       "  835,\n",
       "  1043,\n",
       "  55,\n",
       "  95,\n",
       "  291,\n",
       "  1162,\n",
       "  150,\n",
       "  282,\n",
       "  301,\n",
       "  1268,\n",
       "  536,\n",
       "  665,\n",
       "  829,\n",
       "  1198,\n",
       "  255,\n",
       "  522,\n",
       "  1037,\n",
       "  1054,\n",
       "  1106,\n",
       "  259,\n",
       "  303,\n",
       "  725,\n",
       "  752,\n",
       "  692,\n",
       "  121,\n",
       "  1188,\n",
       "  729,\n",
       "  124,\n",
       "  183,\n",
       "  1176,\n",
       "  33,\n",
       "  956,\n",
       "  328,\n",
       "  531,\n",
       "  481,\n",
       "  384,\n",
       "  1230,\n",
       "  498,\n",
       "  533,\n",
       "  371,\n",
       "  848,\n",
       "  223,\n",
       "  309,\n",
       "  249,\n",
       "  1167,\n",
       "  1049,\n",
       "  985,\n",
       "  25,\n",
       "  1276,\n",
       "  368,\n",
       "  261,\n",
       "  1118,\n",
       "  593,\n",
       "  901,\n",
       "  161,\n",
       "  128,\n",
       "  81,\n",
       "  80,\n",
       "  594,\n",
       "  706,\n",
       "  1187,\n",
       "  944,\n",
       "  395,\n",
       "  718,\n",
       "  143,\n",
       "  868,\n",
       "  577,\n",
       "  813,\n",
       "  1068,\n",
       "  250,\n",
       "  1121,\n",
       "  997,\n",
       "  1197,\n",
       "  1023,\n",
       "  171,\n",
       "  1218,\n",
       "  266,\n",
       "  934,\n",
       "  131,\n",
       "  504,\n",
       "  634,\n",
       "  1132,\n",
       "  972,\n",
       "  489,\n",
       "  154,\n",
       "  444,\n",
       "  1051,\n",
       "  186,\n",
       "  235,\n",
       "  401,\n",
       "  455,\n",
       "  459,\n",
       "  1177,\n",
       "  312,\n",
       "  512,\n",
       "  1133,\n",
       "  474,\n",
       "  325,\n",
       "  127,\n",
       "  1161,\n",
       "  93,\n",
       "  879,\n",
       "  438,\n",
       "  354,\n",
       "  769,\n",
       "  545,\n",
       "  1194,\n",
       "  156,\n",
       "  582,\n",
       "  1263,\n",
       "  298,\n",
       "  194,\n",
       "  608,\n",
       "  89,\n",
       "  613,\n",
       "  404,\n",
       "  960,\n",
       "  843,\n",
       "  860,\n",
       "  1217,\n",
       "  927,\n",
       "  1166,\n",
       "  398,\n",
       "  891,\n",
       "  1025,\n",
       "  1231,\n",
       "  140,\n",
       "  35,\n",
       "  82,\n",
       "  968,\n",
       "  126,\n",
       "  79,\n",
       "  234,\n",
       "  1214,\n",
       "  72,\n",
       "  178,\n",
       "  644,\n",
       "  695,\n",
       "  959,\n",
       "  1124,\n",
       "  654,\n",
       "  1165,\n",
       "  1242,\n",
       "  292,\n",
       "  942,\n",
       "  119,\n",
       "  125,\n",
       "  915,\n",
       "  258,\n",
       "  276,\n",
       "  239,\n",
       "  1274,\n",
       "  607,\n",
       "  636,\n",
       "  914,\n",
       "  715,\n",
       "  196,\n",
       "  801,\n",
       "  358,\n",
       "  1059,\n",
       "  786,\n",
       "  428,\n",
       "  1147,\n",
       "  1226,\n",
       "  554,\n",
       "  1196,\n",
       "  826,\n",
       "  1127,\n",
       "  342,\n",
       "  828,\n",
       "  173,\n",
       "  274,\n",
       "  871,\n",
       "  777,\n",
       "  469,\n",
       "  920,\n",
       "  993,\n",
       "  179,\n",
       "  70,\n",
       "  583,\n",
       "  912,\n",
       "  1027,\n",
       "  895,\n",
       "  682,\n",
       "  687,\n",
       "  492,\n",
       "  129,\n",
       "  873,\n",
       "  612,\n",
       "  767,\n",
       "  1095,\n",
       "  1288,\n",
       "  506,\n",
       "  1072,\n",
       "  496,\n",
       "  419,\n",
       "  703,\n",
       "  907,\n",
       "  256,\n",
       "  650,\n",
       "  700,\n",
       "  1202,\n",
       "  1270,\n",
       "  41,\n",
       "  1120,\n",
       "  170,\n",
       "  973,\n",
       "  567,\n",
       "  1181,\n",
       "  177,\n",
       "  482,\n",
       "  146,\n",
       "  75,\n",
       "  569,\n",
       "  1212,\n",
       "  1011,\n",
       "  388,\n",
       "  759,\n",
       "  440,\n",
       "  1036,\n",
       "  604,\n",
       "  420,\n",
       "  92,\n",
       "  347,\n",
       "  242,\n",
       "  1063,\n",
       "  1123,\n",
       "  198,\n",
       "  1052,\n",
       "  514,\n",
       "  652,\n",
       "  284,\n",
       "  373,\n",
       "  858,\n",
       "  1223,\n",
       "  1144,\n",
       "  892,\n",
       "  899,\n",
       "  1113,\n",
       "  1289,\n",
       "  924,\n",
       "  491,\n",
       "  9,\n",
       "  254,\n",
       "  476,\n",
       "  666,\n",
       "  911,\n",
       "  1042,\n",
       "  574,\n",
       "  139,\n",
       "  943,\n",
       "  550,\n",
       "  721,\n",
       "  300,\n",
       "  283,\n",
       "  310,\n",
       "  592,\n",
       "  641,\n",
       "  632,\n",
       "  1204,\n",
       "  1139,\n",
       "  617,\n",
       "  1066,\n",
       "  1058,\n",
       "  986,\n",
       "  264,\n",
       "  615,\n",
       "  766,\n",
       "  488,\n",
       "  23,\n",
       "  337,\n",
       "  508,\n",
       "  865,\n",
       "  206,\n",
       "  1062,\n",
       "  278,\n",
       "  118,\n",
       "  696,\n",
       "  1,\n",
       "  528,\n",
       "  929,\n",
       "  804,\n",
       "  792,\n",
       "  333,\n",
       "  445,\n",
       "  688,\n",
       "  738,\n",
       "  313,\n",
       "  204,\n",
       "  227,\n",
       "  289,\n",
       "  387,\n",
       "  559,\n",
       "  785,\n",
       "  1287,\n",
       "  137,\n",
       "  940,\n",
       "  396,\n",
       "  918,\n",
       "  810,\n",
       "  1168,\n",
       "  904,\n",
       "  1278,\n",
       "  691,\n",
       "  1209,\n",
       "  815,\n",
       "  370,\n",
       "  1179,\n",
       "  996,\n",
       "  1207,\n",
       "  797,\n",
       "  67,\n",
       "  749,\n",
       "  340,\n",
       "  61,\n",
       "  192,\n",
       "  733,\n",
       "  864,\n",
       "  987,\n",
       "  640,\n",
       "  714,\n",
       "  1029,\n",
       "  707,\n",
       "  576,\n",
       "  238,\n",
       "  304,\n",
       "  827,\n",
       "  58,\n",
       "  1243,\n",
       "  561,\n",
       "  564,\n",
       "  793,\n",
       "  847,\n",
       "  1152,\n",
       "  938,\n",
       "  622,\n",
       "  534,\n",
       "  578,\n",
       "  917,\n",
       "  392,\n",
       "  1213,\n",
       "  745,\n",
       "  51,\n",
       "  674,\n",
       "  237,\n",
       "  185,\n",
       "  280,\n",
       "  754,\n",
       "  557,\n",
       "  439,\n",
       "  746,\n",
       "  231,\n",
       "  408,\n",
       "  1153,\n",
       "  611,\n",
       "  1142,\n",
       "  457,\n",
       "  818,\n",
       "  859,\n",
       "  629,\n",
       "  1065,\n",
       "  1075,\n",
       "  1253,\n",
       "  257,\n",
       "  1057,\n",
       "  1078,\n",
       "  334,\n",
       "  689,\n",
       "  214,\n",
       "  694,\n",
       "  618,\n",
       "  1283,\n",
       "  490,\n",
       "  1284,\n",
       "  353,\n",
       "  1220,\n",
       "  595,\n",
       "  931,\n",
       "  999,\n",
       "  1114,\n",
       "  293,\n",
       "  480,\n",
       "  281,\n",
       "  621,\n",
       "  606,\n",
       "  414,\n",
       "  429,\n",
       "  537,\n",
       "  737,\n",
       "  679,\n",
       "  501,\n",
       "  1126,\n",
       "  590,\n",
       "  1080,\n",
       "  267],\n",
       " 'test': [431,\n",
       "  113,\n",
       "  1216,\n",
       "  625,\n",
       "  326,\n",
       "  790,\n",
       "  510,\n",
       "  167,\n",
       "  87,\n",
       "  566,\n",
       "  913,\n",
       "  919,\n",
       "  1020,\n",
       "  1193,\n",
       "  507,\n",
       "  345,\n",
       "  1103,\n",
       "  98,\n",
       "  1146,\n",
       "  1017,\n",
       "  174,\n",
       "  1000,\n",
       "  252,\n",
       "  43,\n",
       "  525,\n",
       "  1247,\n",
       "  1069,\n",
       "  499,\n",
       "  1199,\n",
       "  421,\n",
       "  460,\n",
       "  357,\n",
       "  1050,\n",
       "  1163,\n",
       "  1280,\n",
       "  556,\n",
       "  382,\n",
       "  1131,\n",
       "  30,\n",
       "  1272,\n",
       "  922,\n",
       "  538,\n",
       "  247,\n",
       "  539,\n",
       "  763,\n",
       "  585,\n",
       "  402,\n",
       "  1206,\n",
       "  1040,\n",
       "  923,\n",
       "  1267,\n",
       "  1190,\n",
       "  849,\n",
       "  897,\n",
       "  180,\n",
       "  524,\n",
       "  1182,\n",
       "  693,\n",
       "  898,\n",
       "  541,\n",
       "  220,\n",
       "  172,\n",
       "  1186,\n",
       "  228,\n",
       "  5,\n",
       "  705,\n",
       "  273,\n",
       "  702,\n",
       "  713,\n",
       "  587,\n",
       "  449,\n",
       "  544,\n",
       "  151,\n",
       "  616,\n",
       "  575,\n",
       "  1089,\n",
       "  442,\n",
       "  548,\n",
       "  639,\n",
       "  1009,\n",
       "  962,\n",
       "  7,\n",
       "  379,\n",
       "  1184,\n",
       "  288,\n",
       "  513,\n",
       "  361,\n",
       "  653,\n",
       "  1079,\n",
       "  377,\n",
       "  816,\n",
       "  461,\n",
       "  425,\n",
       "  1090,\n",
       "  977,\n",
       "  32,\n",
       "  62,\n",
       "  201,\n",
       "  1159,\n",
       "  297,\n",
       "  1261,\n",
       "  108,\n",
       "  517,\n",
       "  684,\n",
       "  648,\n",
       "  1099,\n",
       "  1252,\n",
       "  1100,\n",
       "  45,\n",
       "  2,\n",
       "  1173,\n",
       "  876,\n",
       "  162,\n",
       "  757,\n",
       "  321,\n",
       "  323,\n",
       "  520,\n",
       "  305,\n",
       "  1056,\n",
       "  493,\n",
       "  953,\n",
       "  1264,\n",
       "  967,\n",
       "  866,\n",
       "  413,\n",
       "  160,\n",
       "  348,\n",
       "  881,\n",
       "  542,\n",
       "  112,\n",
       "  399,\n",
       "  1240,\n",
       "  389,\n",
       "  1191,\n",
       "  76,\n",
       "  193,\n",
       "  589,\n",
       "  984,\n",
       "  1189,\n",
       "  378,\n",
       "  133,\n",
       "  686,\n",
       "  822,\n",
       "  225,\n",
       "  422,\n",
       "  367,\n",
       "  1286,\n",
       "  795,\n",
       "  1116,\n",
       "  52,\n",
       "  992,\n",
       "  1273,\n",
       "  643,\n",
       "  867,\n",
       "  182,\n",
       "  350,\n",
       "  497,\n",
       "  870,\n",
       "  562,\n",
       "  1140,\n",
       "  837,\n",
       "  743,\n",
       "  1085,\n",
       "  181,\n",
       "  56,\n",
       "  830,\n",
       "  856,\n",
       "  1102,\n",
       "  54,\n",
       "  906,\n",
       "  94,\n",
       "  588,\n",
       "  732,\n",
       "  410,\n",
       "  1122,\n",
       "  1235,\n",
       "  38,\n",
       "  269,\n",
       "  1008,\n",
       "  555,\n",
       "  1128,\n",
       "  50,\n",
       "  1262,\n",
       "  1081,\n",
       "  875,\n",
       "  850,\n",
       "  411,\n",
       "  1136,\n",
       "  216,\n",
       "  887,\n",
       "  586,\n",
       "  191,\n",
       "  18,\n",
       "  807,\n",
       "  1101,\n",
       "  34,\n",
       "  432,\n",
       "  406,\n",
       "  152,\n",
       "  349,\n",
       "  851,\n",
       "  774,\n",
       "  819,\n",
       "  1032,\n",
       "  1282,\n",
       "  244,\n",
       "  319,\n",
       "  369,\n",
       "  434,\n",
       "  771,\n",
       "  117,\n",
       "  988,\n",
       "  855,\n",
       "  236,\n",
       "  727,\n",
       "  549,\n",
       "  430,\n",
       "  657,\n",
       "  1088,\n",
       "  477,\n",
       "  1224,\n",
       "  711,\n",
       "  458,\n",
       "  558,\n",
       "  1033,\n",
       "  175,\n",
       "  637,\n",
       "  495,\n",
       "  600,\n",
       "  294,\n",
       "  253,\n",
       "  758,\n",
       "  957,\n",
       "  840,\n",
       "  248,\n",
       "  1115,\n",
       "  739,\n",
       "  1160,\n",
       "  708,\n",
       "  91,\n",
       "  1205,\n",
       "  983,\n",
       "  1183,\n",
       "  563,\n",
       "  630,\n",
       "  286,\n",
       "  1092,\n",
       "  681,\n",
       "  740,\n",
       "  831,\n",
       "  596,\n",
       "  787,\n",
       "  1135,\n",
       "  760,\n",
       "  1156,\n",
       "  685,\n",
       "  965,\n",
       "  1028,\n",
       "  839,\n",
       "  356,\n",
       "  246,\n",
       "  344,\n",
       "  1041,\n",
       "  701,\n",
       "  207,\n",
       "  778,\n",
       "  149,\n",
       "  351,\n",
       "  362,\n",
       "  164,\n",
       "  857,\n",
       "  412,\n",
       "  765,\n",
       "  722,\n",
       "  1215,\n",
       "  106,\n",
       "  212,\n",
       "  651,\n",
       "  958,\n",
       "  852,\n",
       "  726,\n",
       "  734,\n",
       "  85,\n",
       "  1221,\n",
       "  102,\n",
       "  416,\n",
       "  29,\n",
       "  838,\n",
       "  649,\n",
       "  31,\n",
       "  1129,\n",
       "  275,\n",
       "  547,\n",
       "  530,\n",
       "  908,\n",
       "  97,\n",
       "  40,\n",
       "  584,\n",
       "  1237,\n",
       "  1236,\n",
       "  1018,\n",
       "  329,\n",
       "  83,\n",
       "  874,\n",
       "  599,\n",
       "  299,\n",
       "  975,\n",
       "  66,\n",
       "  69,\n",
       "  132,\n",
       "  109,\n",
       "  366,\n",
       "  845,\n",
       "  1064,\n",
       "  1227,\n",
       "  699,\n",
       "  68,\n",
       "  796,\n",
       "  624,\n",
       "  832,\n",
       "  123,\n",
       "  153,\n",
       "  1130,\n",
       "  1030,\n",
       "  48,\n",
       "  655,\n",
       "  570,\n",
       "  307,\n",
       "  799,\n",
       "  456,\n",
       "  841,\n",
       "  523,\n",
       "  511,\n",
       "  683,\n",
       "  1067,\n",
       "  103,\n",
       "  552,\n",
       "  882,\n",
       "  565,\n",
       "  994,\n",
       "  317,\n",
       "  755,\n",
       "  27,\n",
       "  73,\n",
       "  543,\n",
       "  42,\n",
       "  659,\n",
       "  374,\n",
       "  671,\n",
       "  1137,\n",
       "  336,\n",
       "  952,\n",
       "  610,\n",
       "  417,\n",
       "  22,\n",
       "  905,\n",
       "  950,\n",
       "  560,\n",
       "  1031,\n",
       "  910,\n",
       "  435,\n",
       "  697,\n",
       "  572,\n",
       "  717,\n",
       "  1281,\n",
       "  780,\n",
       "  478,\n",
       "  872,\n",
       "  720,\n",
       "  821,\n",
       "  219,\n",
       "  166,\n",
       "  452,\n",
       "  78,\n",
       "  833,\n",
       "  553,\n",
       "  142,\n",
       "  1157,\n",
       "  405,\n",
       "  1096,\n",
       "  661,\n",
       "  1022,\n",
       "  673,\n",
       "  100,\n",
       "  890,\n",
       "  741,\n",
       "  451,\n",
       "  176,\n",
       "  773,\n",
       "  211,\n",
       "  1082,\n",
       "  1154,\n",
       "  971,\n",
       "  210,\n",
       "  916,\n",
       "  505,\n",
       "  295,\n",
       "  36,\n",
       "  10,\n",
       "  393,\n",
       "  921,\n",
       "  775,\n",
       "  1005,\n",
       "  59,\n",
       "  736,\n",
       "  1014,\n",
       "  788,\n",
       "  1203,\n",
       "  20,\n",
       "  978,\n",
       "  1251,\n",
       "  15,\n",
       "  372,\n",
       "  964,\n",
       "  208,\n",
       "  263,\n",
       "  483,\n",
       "  400,\n",
       "  805,\n",
       "  723,\n",
       "  834,\n",
       "  980,\n",
       "  218,\n",
       "  279,\n",
       "  339,\n",
       "  781,\n",
       "  6,\n",
       "  716,\n",
       "  205,\n",
       "  1006,\n",
       "  466,\n",
       "  1265,\n",
       "  168,\n",
       "  1111,\n",
       "  951,\n",
       "  381,\n",
       "  1255,\n",
       "  380,\n",
       "  1053,\n",
       "  1084,\n",
       "  932,\n",
       "  603,\n",
       "  436,\n",
       "  57,\n",
       "  735,\n",
       "  1249,\n",
       "  776,\n",
       "  894,\n",
       "  1010,\n",
       "  1105,\n",
       "  928,\n",
       "  646,\n",
       "  1238,\n",
       "  812,\n",
       "  854,\n",
       "  698,\n",
       "  241,\n",
       "  318,\n",
       "  1234,\n",
       "  1148,\n",
       "  680,\n",
       "  631,\n",
       "  772,\n",
       "  302,\n",
       "  203,\n",
       "  1007,\n",
       "  518,\n",
       "  195,\n",
       "  277,\n",
       "  262,\n",
       "  471,\n",
       "  1077,\n",
       "  1004,\n",
       "  60,\n",
       "  719,\n",
       "  1170,\n",
       "  1107,\n",
       "  327,\n",
       "  900,\n",
       "  199,\n",
       "  64,\n",
       "  877,\n",
       "  437,\n",
       "  16,\n",
       "  245,\n",
       "  3,\n",
       "  189,\n",
       "  761,\n",
       "  768,\n",
       "  1061,\n",
       "  1257,\n",
       "  145,\n",
       "  1180,\n",
       "  190,\n",
       "  747,\n",
       "  462,\n",
       "  484,\n",
       "  1125,\n",
       "  581,\n",
       "  753,\n",
       "  114,\n",
       "  954,\n",
       "  120,\n",
       "  1192,\n",
       "  1269,\n",
       "  110,\n",
       "  1271,\n",
       "  1055,\n",
       "  789,\n",
       "  981,\n",
       "  360,\n",
       "  1172,\n",
       "  232,\n",
       "  138,\n",
       "  690,\n",
       "  660,\n",
       "  880,\n",
       "  602,\n",
       "  529,\n",
       "  365,\n",
       "  14,\n",
       "  933,\n",
       "  1045,\n",
       "  909,\n",
       "  448,\n",
       "  453,\n",
       "  1233,\n",
       "  12,\n",
       "  597,\n",
       "  635,\n",
       "  1138,\n",
       "  306,\n",
       "  1003,\n",
       "  989,\n",
       "  409,\n",
       "  1021,\n",
       "  836,\n",
       "  105,\n",
       "  750,\n",
       "  155,\n",
       "  791,\n",
       "  1048,\n",
       "  1086,\n",
       "  229,\n",
       "  939,\n",
       "  863,\n",
       "  104,\n",
       "  1208,\n",
       "  1150,\n",
       "  519,\n",
       "  1245,\n",
       "  516,\n",
       "  628,\n",
       "  926,\n",
       "  1171,\n",
       "  663,\n",
       "  598,\n",
       "  658,\n",
       "  47,\n",
       "  1149,\n",
       "  159,\n",
       "  814,\n",
       "  1260,\n",
       "  1134,\n",
       "  221,\n",
       "  678,\n",
       "  509,\n",
       "  677,\n",
       "  165,\n",
       "  842,\n",
       "  224,\n",
       "  394,\n",
       "  1254,\n",
       "  53,\n",
       "  535,\n",
       "  817,\n",
       "  230,\n",
       "  995,\n",
       "  546,\n",
       "  1145,\n",
       "  1250,\n",
       "  526,\n",
       "  571,\n",
       "  945,\n",
       "  620,\n",
       "  46,\n",
       "  209,\n",
       "  243,\n",
       "  37,\n",
       "  885,\n",
       "  0,\n",
       "  446,\n",
       "  260,\n",
       "  1158,\n",
       "  762,\n",
       "  903,\n",
       "  1185,\n",
       "  485,\n",
       "  322,\n",
       "  11,\n",
       "  1151,\n",
       "  17,\n",
       "  1001,\n",
       "  65,\n",
       "  450,\n",
       "  970,\n",
       "  107,\n",
       "  998,\n",
       "  8,\n",
       "  966,\n",
       "  1228,\n",
       "  579,\n",
       "  19,\n",
       "  800,\n",
       "  158,\n",
       "  1013,\n",
       "  521,\n",
       "  770,\n",
       "  974,\n",
       "  853,\n",
       "  63,\n",
       "  1164,\n",
       "  751,\n",
       "  1104,\n",
       "  494,\n",
       "  1083,\n",
       "  1277,\n",
       "  500,\n",
       "  1244,\n",
       "  1094,\n",
       "  355,\n",
       "  782,\n",
       "  418,\n",
       "  946,\n",
       "  1091,\n",
       "  122,\n",
       "  601,\n",
       "  1110,\n",
       "  271,\n",
       "  1225,\n",
       "  324,\n",
       "  270,\n",
       "  86,\n",
       "  1024,\n",
       "  90]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Splits['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Splits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25ce305a386a39a7d45e9afabe845f2531ef4af69c8f568c4ee3eb835efb2d66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
